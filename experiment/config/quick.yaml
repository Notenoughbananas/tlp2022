log_folder: 'log_quick'

# Used to quickly test a model or dataset. Simply uncomment the model or dataset you want to run. (last uncommented model/dataset is used)
#model: gcn
#model: gat
#model: seal
#model: egcn_h
model: gclstm
#model: tgat
#model: tgn
#model: cn
#model: aa
#model: ccpa
#model: random
#model: random_heuristic
#model: random_adaptive
#model: mdgnn

#data: enron
#data: uc
#data: bitcoin-otc
#data: bitcoin-otc
#data: bitcoin-alpha
#data: autonomous-systems
#data: wikipedia
#data: reddit
data: wsdm-A
#data: wsdm-B

#one_cell: True
save_predictions: True
use_cuda: True
use_logfile: False #True/False
notify: False
skip_computed_grid_cells: False
run_downstream: False
#force_encode: True
full_test_during_run: True
final_epoch: False

has_time_query: True
weekday_filter: "weekdays"
max_label_links: 1000
#max_continuous_links: 5000 # 5000000 # 5 mill. Up to 10 mill might be ok.
min_node_emb_size: 55
custom_labeler: True
#eval_only: True
#eval_only_last: True
#eval_only: False
#eval_only_last: False

#Dataset
strictly_evolving: False

#Heuristics
include_existing_edges: False #'adaptive' #False

negative_mult_training: 10
random_feats: False
learning_rate:
    - 0.0001
decoder_learning_rate:
    - 0.01
decoder_weight_decay:
    - 0.01
num_epochs: 10
num_epochs_continuous: 10
eval_after_epochs: 0
num_hist_steps: 1 #'expanding' #'static' #1 #10 #'static' # 1 # number of previous steps used for prediction

rand_idx_rate: 0.0
rand_etype_rate: 0.0
rand_time_rate: 0.0

decoder_time_encoder_dim: 10
decoder_edge_type_emb_dim: 90
decoder_time_emb_dim: 30

seed: 1235
data_loading_params:
  batch_size: 1
  num_workers: 1

node_features: ['degree']
link_features: ['cn', 'invspl']

gcn_parameters:
  # GAT, TGAT and TGN
  attention_heads: 2
  dropout: 0.1
  # TGN
  use_memory: True

  # EGCN
  k_top_grcu: 200

  # GC-LSTM
  K: 3

  # SEAL
  hops: 2
  seal_k: 10

  # MDGNN
  model: "gclstm"

  # All
  layer_1_feats: 172
  layer_2_feats_same_as_l1: True
  num_layers: 2 #Often doesn't do anything, most models have 2 layers hard coded
  cls_feats: 10

cont_gcn_parameters:
  # GAT, TGAT and TGN
  attention_heads: 2
  dropout: 0.1
  # TGN
  use_memory: True

  # EGCN
  k_top_grcu: 200

  # GC-LSTM
  K: 3

  # SEAL
  hops: 2
  seal_k: 10

  # mdgnn
  model: "tgat"

  # All
  layer_1_feats: 10
  layer_2_feats_same_as_l1: True
  num_layers: 2 #Often doesn't do anything, most models have 2 layers hard coded
  cls_feats: 10
